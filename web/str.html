<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width">
  <title>Program</title>
  <link rel="stylesheet" href="https://pyscript.net/latest/pyscript.css" />
  <script defer src="https://pyscript.net/latest/pyscript.js"></script>
  <link rel="icon" type = "image/png" href="/log.png">
  <link rel="stylesheet" href="style.css"
</head>

<body>
  <div align = "center" class = "content">
      <img src = "log.png" alt="icon" class="logo">
      <h2>Parser</h2>
      <input type = "text" id="chatid" placeholder="Сhatid"><br>
      <input type = "text" id="url" placeholder="URL"></textarea><br>
      <button id = "send_message">Спарсить и отправить</button>
      <p id="result"></p>
  </div>
  <py-script>
    import os
    import csv
    import eel
    import telebot
    import eel
    from bs4 import BeautifulSoup
    import requests
    from requests import get, Response
    import os
    
    
    
    PATH = 'Cars.csv'
    URL = os.getenv('URL')
    COOKIE = os.getenv('COOKIE')
    HEADERS = {
        'user-agent': os.getenv('USER_AGENT'),
        'accept': os.getenv('ACCEPT'),
        'Accept-Language': 'ru',
        'accept-encoding': 'accept - encoding: gzip, deflate, br',
        'sec-ch-ua': '" Not A;Brand";v="99", "Chromium";v="101", "Opera";v="87"',
        'sec-ch-ua-mobile': '?0',
        'sec-ch-ua-platform': '"Windows"',
        'Upgrade-Insecure-Requests': '1',
        'Cookie': COOKIE
    }
    
    token='6359779765:AAH_VH-UsgY4ZdU1FnZHHm1HemOSnPjdpCs'
    bot=telebot.TeleBot(token)
    
    @eel.expose
    def parse_auto(url,chat_id):
        html = requests.get(url, HEADERS)
        if html.status_code == 200:
            cars = []
            soup = BeautifulSoup(html.content, 'html.parser')
            pages_amount = int(len(soup.find('span',class_='ControlGroup ControlGroup_responsive_no ControlGroup_size_s ListingPagination__pages').contents))
            for i in range(1, pages_amount + 1):
                print(f'Парсим {i} страницу из {pages_amount}...')
                html = requests.get(url, HEADERS, params={'page': i})
                soup1 = BeautifulSoup(html, 'html.parser')
                items = soup1.find_all('div', class_='ListingItem__description')
                for item in items:
                    car = {
                        'car': item.find('div', 'ListingItem__summary').get_text(),
                        'url': item.find('a', 'Link ListingItemTitle__link').get('href'),
                        'price': item.find('div', 'ListingItemPrice__content').get_text().replace(' ', '').replace('₽', ''),
                        'year': item.find('div', 'ListingItem__yearBlock').get_text(),
                    }
                    cars.append(car)
            print(f'Получены данные по {len(cars)} авто.')
            cars1 = sorted(cars, key=lambda car: int(car['year']), reverse=True)
            with open(PATH, 'w', newline='', encoding='utf-8') as file:
                w = csv.writer(file, delimiter=';')
                w.writerow(['Car', 'Link', 'Price (RUR)', 'Year'])
                for car in cars1:
                    w.writerow([
                        car['car'],
                        car['url'],
                        car['price'],
                        car['year']
                    ])
                os.startfile(PATH)
            file = open('Cars.csv', 'rb')
            bot.send_document(chat_id=chat_id,document=file)
            file.close()
        </py-script>
</body>
</html>